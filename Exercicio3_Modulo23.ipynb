{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNmOAtE+aa7l00HulPY+wTa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/suelen-prs/-ebac-ciencia-de-dados-modulo-3-parte-2/blob/master/Exercicio3_Modulo23.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDbuYakwPyuI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Quais são os hyperparâmetrosdo RF?\n",
        "# 2. Pra que serve cada um deles?"
      ],
      "metadata": {
        "id": "JRIzMwx8P_Rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**n_estimators:** Este é o número de árvores na floresta. Geralmente, quanto mais árvores, melhor será a capacidade do modelo de generalizar, mas isso também aumenta o custo computacional.\n",
        "\n",
        "**max_depth:** A profundidade máxima das árvores. Limitar a profundidade pode ajudar a prevenir overfitting. Se não for definido, as árvores crescerão até que cada folha seja pura ou contenha menos amostras que o mínimo necessário para dividir um nó.\n",
        "\n",
        "**min_samples_split:** O número mínimo de amostras necessário para dividir um nó interno. Valores maiores previnem a criação de árvores muito específicas e podem ajudar a evitar overfitting.\n",
        "\n",
        "**min_samples_leaf:** O número mínimo de amostras requerido para ser uma folha (nó final) de uma árvore. Assim como o min_samples_split, pode ajudar a aumentar a generalização do modelo ao evitar folhas com poucas amostras.\n",
        "\n",
        "**max_features:** O número de features a considerar ao procurar a melhor divisão. Dependendo do valor (pode ser um número inteiro, float, \"auto\", \"sqrt\", \"log2\"), isso limita o número de features e ajuda a aumentar a diversidade entre as árvores, potencialmente aumentando a performance do modelo.\n",
        "\n",
        "**bootstrap:** Se o bootstrap será usado ao construir árvores. Se falso, o modelo utilizará todo o dataset para construir cada árvore. Geralmente, bootstrap=True é recomendado para aproveitar o efeito de redução de variância do Random Forest.\n",
        "\n",
        "**oob_score:** Se deve usar amostras out-of-bag para estimar a precisão do modelo. Isso é útil para aproveitar ao máximo o conjunto de dados de treinamento, usando algumas amostras para treinar e outras para validar o modelo.\n",
        "\n",
        "**n_jobs:** Indica o número de processadores a serem usados para treinar e prever. Um valor de -1 significa usar todos os processadores disponíveis, potencialmente diminuindo o tempo de treinamento.\n",
        "\n",
        "**random_state:** Controla a aleatoriedade do bootstrapping e da seleção de features. Definir um valor fixo garante que os resultados sejam reproduzíveis.\n",
        "\n",
        "**max_leaf_nodes:** Limita o número de nós folha nas árvores. Pode ser usado em vez de max_depth para controle mais fino do tamanho das árvores."
      ],
      "metadata": {
        "id": "HEvGivMrQkyK"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IQiepohPQDYF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}